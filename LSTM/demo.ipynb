{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do\n",
    "\n",
    "1. Consider pickling the model instead of putting it in here\n",
    "2. Also consider storing all the helper functions in a separate python file\n",
    "3. Decoder text and listen\n",
    "4. Consider sequencing the interactions, to save all outputs\n",
    "5. Stylize the piano to be nicer\n",
    "6. Add acknowledgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import (\n",
    "    Audio, display, clear_output)\n",
    "from ipywidgets import widgets, Button, Layout, ButtonStyle\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up 3 helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to play corresponding.wav file of piano note\n",
    "def play(noteIdx):\n",
    "    wavfile = '61-notes-piano/piano-ff-' + noteIdx + '.wav'\n",
    "    display(Audio(wavfile, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a deciated output widget, play the sound when a button is clicked\n",
    "def on_button_clicked(noteIdx, b):\n",
    "    with widgets.Output():\n",
    "        play(noteIdx)\n",
    "        sequence.append(int(noteIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sequence from piano into input text\n",
    "def intToText(int_seq):\n",
    "    text_seq = []\n",
    "    for i in int_seq:\n",
    "        text_seq.append(\"p\"+str(i))\n",
    "        text_seq.append(\"wait6\")\n",
    "    return \" \".join(text_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styling the widgets to resemble piano keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# css for white keys\n",
    "layout_white = widgets.Layout(\n",
    "    width='40px', height='200px',\n",
    "    padding = '1px',\n",
    "    border='1px solid black')\n",
    "\n",
    "# css for black keys\n",
    "layout_black = widgets.Layout(\n",
    "    width='40px', height='200px',\n",
    "    padding = '1px',\n",
    "    border='1px solid black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word2int dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with any text file containing full set of data\n",
    "mozart_data = './mozart.txt'\n",
    "\n",
    "with open(mozart_data, 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# get vocabulary set\n",
    "words = sorted(tuple(set(text.split())))\n",
    "n = len(words)\n",
    "\n",
    "# create word-integer encoder/decoder\n",
    "word2int = dict(zip(words, list(range(n))))\n",
    "int2word = dict(zip(list(range(n)), words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural net\n",
    "class WordLSTM(nn.ModuleList):\n",
    "    \n",
    "    def __init__(self, sequence_len, vocab_size, hidden_dim, batch_size):\n",
    "        super(WordLSTM, self).__init__()\n",
    "        \n",
    "        # init the hyperparameters\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_len = sequence_len\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # first layer lstm cell\n",
    "        self.lstm_1 = nn.LSTMCell(input_size=vocab_size, hidden_size=hidden_dim)\n",
    "        \n",
    "        # second layer lstm cell\n",
    "        self.lstm_2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
    "        \n",
    "    # forward pass in training   \n",
    "    def forward(self, x, hc):\n",
    "        \"\"\"\n",
    "            accepts 2 arguments: \n",
    "            1. x: input of each batch \n",
    "                - shape 128*149 (batch_size*vocab_size)\n",
    "            2. hc: tuple of init hidden, cell states \n",
    "                - each of shape 128*512 (batch_size*hidden_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # create empty output seq\n",
    "        output_seq = torch.empty((self.sequence_len,\n",
    "                                  self.batch_size,\n",
    "                                  self.vocab_size))\n",
    "        # if using gpu        \n",
    "        output_seq = output_seq.to(device)\n",
    "        \n",
    "        # init hidden, cell states for lstm layers\n",
    "        hc_1, hc_2 = hc, hc\n",
    "        \n",
    "        # for t-th word in every sequence \n",
    "        for t in range(self.sequence_len):\n",
    "            \n",
    "            # layer 1 lstm\n",
    "            hc_1 = self.lstm_1(x[t], hc_1)\n",
    "            h_1, c_1 = hc_1\n",
    "            \n",
    "            # layer 2 lstm\n",
    "            hc_2 = self.lstm_2(h_1, hc_2)\n",
    "            h_2, c_2 = hc_2\n",
    "            \n",
    "            # dropout and fully connected layer\n",
    "            output_seq[t] = self.fc(self.dropout(h_2))\n",
    "            \n",
    "        return output_seq.view((self.sequence_len * self.batch_size, -1))\n",
    "          \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        # initialize hidden, cell states for training\n",
    "        # if using gpu\n",
    "        return (torch.zeros(self.batch_size, self.hidden_dim).to(device),\n",
    "                torch.zeros(self.batch_size, self.hidden_dim).to(device))\n",
    "    \n",
    "    def init_hidden_generator(self):\n",
    "        \n",
    "        # initialize hidden, cell states for prediction of 1 sequence\n",
    "        # if using gpu\n",
    "        return (torch.zeros(1, self.hidden_dim).to(device),\n",
    "                torch.zeros(1, self.hidden_dim).to(device))\n",
    "    \n",
    "    def predict(self, seed_seq, top_k=5, pred_len=256):\n",
    "        \"\"\"\n",
    "            accepts 3 arguments: \n",
    "            1. seed_seq: seed string sequence for prediction (prompt)\n",
    "            2. top_k: top k words to sample prediction from\n",
    "            3. pred_len: number of words to generate after the seed seq\n",
    "        \"\"\"\n",
    "        \n",
    "        # set evaluation mode\n",
    "        self.eval()\n",
    "        \n",
    "        # split string into list of words\n",
    "        seed_seq = seed_seq.split()\n",
    "        \n",
    "        # get seed sequence length\n",
    "        seed_len = len(seed_seq)\n",
    "        \n",
    "        # create output sequence\n",
    "        out_seq = np.empty(seed_len+pred_len)\n",
    "        \n",
    "        # append input seq to output seq\n",
    "        out_seq[:seed_len] = np.array([word2int[word] for word in seed_seq])\n",
    " \n",
    "        # init hidden, cell states for generation\n",
    "        hc = self.init_hidden_generator()\n",
    "        hc_1, hc_2 = hc, hc\n",
    "        \n",
    "        # feed seed string into lstm\n",
    "        # get the hidden state set up\n",
    "        for word in seed_seq[:-1]:\n",
    "            \n",
    "            # encode starting word to one-hot encoding\n",
    "            word = to_categorical(word2int[word], num_classes=self.vocab_size)\n",
    "\n",
    "            # add batch dimension\n",
    "            word = torch.from_numpy(word).unsqueeze(0)\n",
    "            # if using gpu\n",
    "            word = word.to(device) \n",
    "            \n",
    "            # layer 1 lstm\n",
    "            hc_1 = self.lstm_1(word, hc_1)\n",
    "            h_1, c_1 = hc_1\n",
    "            \n",
    "            # layer 2 lstm\n",
    "            hc_2 = self.lstm_2(h_1, hc_2)\n",
    "            h_2, c_2 = hc_2\n",
    "        \n",
    "        word = seed_seq[-1]\n",
    "        \n",
    "        # encode starting word to one-hot encoding\n",
    "        word = to_categorical(word2int[word], num_classes=self.vocab_size)\n",
    "\n",
    "        # add batch dimension\n",
    "        word = torch.from_numpy(word).unsqueeze(0)\n",
    "        # if using gpu\n",
    "        word = word.to(device) \n",
    "\n",
    "        # forward pass\n",
    "        for t in range(pred_len):\n",
    "            \n",
    "            # layer 1 lstm\n",
    "            hc_1 = self.lstm_1(word, hc_1)\n",
    "            h_1, c_1 = hc_1\n",
    "            \n",
    "            # layer 2 lstm\n",
    "            hc_2 = self.lstm_2(h_1, hc_2)\n",
    "            h_2, c_2 = hc_2\n",
    "            \n",
    "            # fully connected layer without dropout (no need)\n",
    "            output = self.fc(h_2)\n",
    "            \n",
    "            # software to get probabilities of output options\n",
    "            output = F.softmax(output, dim=1)\n",
    "            \n",
    "            # get top k words and corresponding probabilities\n",
    "            p, top_word = output.topk(top_k)\n",
    "            # if using gpu           \n",
    "            p = p.cpu()\n",
    "            \n",
    "            # sample from top k words to get next word\n",
    "            p = p.detach().squeeze().numpy()\n",
    "            top_word = torch.squeeze(top_word)\n",
    "            \n",
    "            word = np.random.choice(top_word, p = p/p.sum())\n",
    "            \n",
    "            # add word to sequence\n",
    "            out_seq[seed_len+t] = word\n",
    "            \n",
    "            # encode predicted word to one-hot encoding for next step\n",
    "            word = to_categorical(word, num_classes=self.vocab_size)\n",
    "            word = torch.from_numpy(word).unsqueeze(0)\n",
    "            # if using gpu\n",
    "            word = word.to(device)\n",
    "            \n",
    "        return out_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run only one of the following cells\n",
    "\n",
    "1. **25-keys** piano OR\n",
    "2. **49-keys** piano OR\n",
    "3. **61-keys** piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes for 25 keys piano\n",
    "octave = \"C,C#,D,D#,E,F,F#,G,G#,A,A#,B,\"\n",
    "notes = (octave*2).split(\",\")\n",
    "notes[-1] = \"C\"\n",
    "\n",
    "# note index for 25 key piano\n",
    "noteIdxs = [(\"00\"+str(i))[-3:]  for i in range(25,50)]\n",
    "\n",
    "noteDict = list(zip(notes, noteIdxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes for 49 keys piano\n",
    "octave = \"C,C#,D,D#,E,F,F#,G,G#,A,A#,B,\"\n",
    "notes = (octave*4).split(\",\")\n",
    "notes[-1] = \"C\"\n",
    "\n",
    "# note index for 49 key piano\n",
    "noteIdxs = [(\"00\"+str(i))[-3:]  for i in range(13,62)]\n",
    "\n",
    "noteDict = list(zip(notes, noteIdxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes for 61 keys piano\n",
    "octave = \"C,C#,D,D#,E,F,F#,G,G#,A,A#,B,\"\n",
    "notes = (octave*5).split(\",\")\n",
    "notes[-1] = \"C\"\n",
    "\n",
    "# note index for 61 key piano\n",
    "noteIdxs = [(\"00\"+str(i))[-3:]  for i in range(1,62)]\n",
    "\n",
    "# zip notes and index into tuples\n",
    "noteDict = list(zip(notes, noteIdxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTMCell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_path = './models/lstm20_ed'\n",
    "model = torch.load(model_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Play a starting tune\n",
    "\n",
    "Re-run the cell to clear and reset the starting tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f5b754b86142909048912ebfc72652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Button(description='C', layout=Layout(border='1px solid black', height='200px', padding='1px', wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init buttons and seed sequence\n",
    "buttons, sequence = [], []\n",
    "\n",
    "for note, noteIdx in noteDict:\n",
    "    if '#' in note:\n",
    "        button = widgets.Button(\n",
    "            description=note, layout=layout_black, style=ButtonStyle(button_color='gray'))     \n",
    "    else:\n",
    "        button = widgets.Button(\n",
    "            description=note, layout=layout_white, style=ButtonStyle(button_color='white'))\n",
    "\n",
    "    button.on_click(partial(on_button_clicked, noteIdx))\n",
    "    buttons.append(button)\n",
    "\n",
    "# We place all buttons horizontally.\n",
    "widgets.Box(children=buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 32, 38, 39, 40, 45]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Let maia complete the piece for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format piano sequence into input text\n",
    "seed_seq = intToText(sequence)\n",
    "\n",
    "# predict using model\n",
    "output_text = ' '.join([int2word[int_] for int_ in model.predict(seed_seq, pred_len=256)])\n",
    "\n",
    "timestamp = str(int(time.time()))\n",
    "\n",
    "filename = \"generated\"+timestamp+\".txt\"\n",
    "\n",
    "with open(\"../demo/output/text/\"+filename, \"w\") as outfile:\n",
    "    outfile.write(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Enjoy the final piece finished by maia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Decoded midi file saved to '/output/midi/'\n"
     ]
    }
   ],
   "source": [
    "import decoder\n",
    "decoder.main(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://freesound.org/people/jobro/packs/2489/?page=1#sound\n",
    "\n",
    "Sound pack downloaded from Freesound\n",
    "----------------------------------------\n",
    "\n",
    "This pack of sounds contains sounds by the following user:\n",
    " - jobro ( https://freesound.org/people/jobro/ )\n",
    "\n",
    "You can find this pack online at: https://freesound.org/people/jobro/packs/2489/\n",
    "\n",
    "License details\n",
    "---------------\n",
    "\n",
    "Attribution: http://creativecommons.org/licenses/by/3.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes for 88 keys piano\n",
    "octave = \"C,C#,D,D#,E,F,F#,G,G#,A,A#,B,\"\n",
    "notes = (octave*8).split(\",\")\n",
    "notes[-1] = \"C\"\n",
    "\n",
    "# note index for 88 key piano\n",
    "noteIdxs = [(\"00\"+str(i))[-3:]  for i in range(1,89)]\n",
    "\n",
    "noteDict = list(zip(notes[9:], noteIdxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
